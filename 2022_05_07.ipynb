{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022_05_07.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcDwXAr0aQ1G"
      },
      "outputs": [],
      "source": [
        "from numba import cuda, jit, float32\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True)\n",
        "def inner_product(x, y):\n",
        "    out = 0\n",
        "    \n",
        "    for i in range(x.size):\n",
        "        out += x[i] * y[i]\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "tFHxRqxaIDO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(nopython=True)\n",
        "def inner_product_for_grad(x, y, b):\n",
        "    out = b * (-1)\n",
        "    \n",
        "    for i in range(x.size):\n",
        "        out += x[i] * y[i]\n",
        "    \n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "z6qDjMawRSF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def matrix_vector_multiplication(A, x, b, out):\n",
        "    tx = cuda.threadIdx.x\n",
        "    bx = cuda.blockIdx.x\n",
        "\n",
        "    i = bx * TPB + tx\n",
        "\n",
        "    if i < out.shape[0]:\n",
        "        out[i] = inner_product_for_grad(A[i,:], x, b[i])"
      ],
      "metadata": {
        "id": "KOqhjdzNZzPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TPB = 16\n",
        "\n",
        "@cuda.jit\n",
        "def get_grad(A, x, b, out):\n",
        "    sA = cuda.shared.array(shape=(TPB,TPB), dtype=float32)\n",
        "    sB = cuda.shared.array(shape=(TPB), dtype=float32)\n",
        "\n",
        "    i = cuda.grid(1)\n",
        "\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "\n",
        "    if i >= out.shape[0]:\n",
        "        ## Quit if (x) is outside of valid out boundary\n",
        "        return\n",
        "\n",
        "    tmp = 0.\n",
        "    for j in range(int(A.shape[0] / TPB)):\n",
        "        ## Preload data into shared memory\n",
        "        sA[tx, ty] = A.T[i, ty + j * TPB]\n",
        "        sB[tx] = inner_product_for_grad(A[tx + j * TPB,:], x, b[tx + j * TPB])\n",
        "\n",
        "        ## Wait until all threads finish proloading\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        ## Computes partial product on the shared memory\n",
        "        for k in range(TPB):\n",
        "            tmp += sA[tx, k] * sB[tx]\n",
        "\n",
        "        ## Wait until all threads finish computing\n",
        "        cuda.syncthreads()\n",
        "\n",
        "    out[i] = tmp"
      ],
      "metadata": {
        "id": "AUzaE-gBImjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.rand(10000,1000)\n",
        "b = np.random.rand(10000)\n",
        "x = np.random.rand(1000)\n",
        "out = np.zeros((1000))"
      ],
      "metadata": {
        "id": "gqxAX-owVnVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## In CPU with numpy\n",
        "%%time \n",
        "for i in range(100):\n",
        "    grad = A.T @ (A @ x - b)\n",
        "## almost 660 us takes to calculate "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONPbwl5WWzkB",
        "outputId": "ffd43911-ef0d-4359-b4f7-d6404a4f3305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.14 s, sys: 215 ms, total: 2.36 s\n",
            "Wall time: 1.46 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_ = cuda.to_device(A)\n",
        "b_ = cuda.to_device(b)\n",
        "x_ = cuda.to_device(x)\n",
        "out_ = cuda.to_device(out)"
      ],
      "metadata": {
        "id": "BoKJ7M2CVuSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Configure the blocks\n",
        "threadsperblock = (TPB,TPB)\n",
        "blockspergrid_x = int(np.ceil(A.shape[0] / threadsperblock[1]))\n",
        "blockspergrid_y = int(np.ceil(A.shape[1] / threadsperblock[0]))\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "get_grad[blockspergrid, threadsperblock](A_, x_, b_, out_)"
      ],
      "metadata": {
        "id": "9KnQ0tqoV0b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Start the kernel\n",
        "%%time \n",
        "for i in range(100):\n",
        "    get_grad[blockspergrid, threadsperblock](A_, x_, b_, out_)\n",
        "## almost 600 us takes to calculate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouWFEKaxaX2U",
        "outputId": "badbef8d-9ada-42b0-d196-87023f257c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 68.5 ms, sys: 429 µs, total: 68.9 ms\n",
            "Wall time: 125 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2022_04_26.ipynb 에서 사용한 이상한... numba 사용말고 조금 더 개선된 방법(__shared memory__를 사용하는 방법)으로 gradient를 계산하는 것을 구현했습니다... 속도는 좀더 개선되었습니다...<br>\n",
        "조금 걱정되는 것은 초반에 cuda.synchronize()로 thread들을 정렬시키는데에 시간이 꽤 오래걸려 실제 사용중에도 시간이 오래걸리는 원인이 되지 않을까 걱정됩니다... 오히려 없는것이 더 빠른 요상한 경우가 있네요...<br>\n",
        "> @jit 데코레이터는 첫번째 컴파일시 코드를 조금 변형해 더 빠르게 만들어 주므로, 첫번째 컴파일은 굉장히(상대적으로) 오래걸립니다. 마치 C언어를 컴파일하는 느낌으로 이해하면 잘 와다았습니다.<br>\n",
        "\n",
        "그리고 또, 실질적으로 학습시에 CPU, GPU간 통신의 latency 로 여기서 얻은 시간 단축이 무용지물이 될 가능성도 염두해두고 있습니다...<br>\n",
        "마지막으로 오차가 0.0361이나 되는 것이 걱정됩니다... 계산상 과정은 똑같은데 세분화되면서 오차가 누적되었나 싶기도 하네요... 오차 계산시에 1e-6을 곱해준 것은 실질적인 learning rate가 $lr = \\frac{1e-3}{A.shape[0]}$으로 계산되어서 $A.shape[0] = 1000$을 대입해준 $lr = 1e-6$입니다. 이러니 오차가 굉장히 크네요."
      ],
      "metadata": {
        "id": "uT7o2Ja2vC9u"
      }
    }
  ]
}